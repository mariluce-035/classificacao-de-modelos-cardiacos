{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',500)\n",
    "pd.set_option('display.max_rows',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para estratificar o dataset em k folds\n",
    "\n",
    "def stratify_dataset(dataset, k):\n",
    "    # Define qual será o dataset\n",
    "    if dataset == 'dados_normalizados_aumentados_minmax':\n",
    "        dataset_file = pd.read_csv(\"../Database/df_database_dados_normalizados_aumentados_minmax.csv\")\n",
    "    \n",
    "    if dataset == 'dados_normalizados_aumentados_minmax_morfologicos':\n",
    "        dataset_file = pd.read_csv(\"../Database/df_database_dados_normalizados_aumentados_minmax_morfologicos.csv\")\n",
    "    \n",
    "    # Separa a coluna target das características\n",
    "    dataset_features = dataset_file.drop('target', axis=1)\n",
    "    y = dataset_file.loc[:, 'target']\n",
    "\n",
    "    # Transformando para numpy\n",
    "    #dataset_features = dataset_features.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)\n",
    "    X = dataset_features.to_numpy()\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits = k, shuffle = True, random_state = 1)\n",
    "    \n",
    "    return dataset_file, X, y, cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = 'dados_normalizados_aumentados_minmax'\n",
    "dataset = 'dados_normalizados_aumentados_minmax_morfologicos'\n",
    "k = 10\n",
    "\n",
    "dataset_file, X, y, cv = stratify_dataset(dataset, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possíveis validações para valores nulos/ausentes ou infinitos\n",
    "\n",
    "#print(np.count_nonzero(np.isnan(X)))     # True wherever nan\n",
    "#print(np.count_nonzero(np.isposinf(X)))  # True wherever pos-inf\n",
    "#print(np.count_nonzero(np.isneginf(X)))  # True wherever neg-inf\n",
    "#print(np.count_nonzero(np.isinf(X)))     # True wherever pos-inf or neg-inf\n",
    "#print(np.count_nonzero(~np.isfinite(X))) # True wherever pos-inf or neg-inf or nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de parâmetros de treinamento e de teste para cada modelo considerado \n",
    "\n",
    "models_parameters = {\n",
    "    'GaussianNB': {\n",
    "        'model': GaussianNB(),\n",
    "        'params': {\n",
    "            'var_smoothing': [1e-9,1e-8,1e-7,1e-6,1e-5,0.0001,0.001,0.01,0.1,0.2]\n",
    "        }\n",
    "    },  \n",
    "    'BernoulliNB':{\n",
    "        'model': BernoulliNB(),\n",
    "        'params': {\n",
    "            'alpha':[0.0,0.001,0.01,0.1,0.2,0.5,1,1.5,10,20],\n",
    "            'binarize':[0.0,0.001,0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "        }\n",
    "    },\n",
    "    'MLPClassifier': {\n",
    "        'model': MLPClassifier(),\n",
    "        'params': {\n",
    "            'max_iter': [30, 60, 90, 120, 150, 200],\n",
    "            'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "            'learning_rate_init': [0.001, 0.01, 0.05, 0.1]\n",
    "        }\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "         'model': RandomForestClassifier(),\n",
    "         'params': {\n",
    "             'n_estimators': [10,100,250,500,750,1000],\n",
    "             'criterion': ['gini', 'entropy'],\n",
    "             'max_features': ['sqrt','log2',None],\n",
    "             'n_jobs': [-1],\n",
    "             'ccp_alpha': [0.0,0.02,0.04,0.08,0.16,0.32,0.64,1.28]\n",
    "         }\n",
    "    },\n",
    "    'LinearSVC': {\n",
    "         'model': LinearSVC(),\n",
    "         'params': {\n",
    "             'loss': ['hinge', 'squared_hinge'],\n",
    "             'tol': [1e-4, 1e-3, 1e-2, 0.1],\n",
    "             'C': [1.0, 10.0, 100.0],\n",
    "             'multi_class': ['ovr'],\n",
    "             'max_iter': [1000, 2500, 5000, 7500, 10000]\n",
    "         }\n",
    "    },\n",
    "    'SVC':{\n",
    "        'model': SVC(),\n",
    "        'params': {\n",
    "            'C': [0.001,0.01,0.1,0.5,1.0,1.5,5,10,20],\n",
    "            'kernel': ['rbf','linear','poly','sigmoid'],\n",
    "            'gamma': ['auto','scale',0.001,0.01,0.1]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de métricas para rankeamento nos testes\n",
    "\n",
    "scoring = {\n",
    "    'roc_auc_ovr_scorer': make_scorer(roc_auc_score, average='macro', needs_proba = True, multi_class='ovr'),\n",
    "    #'roc_auc_ovo_scorer': make_scorer(roc_auc_score, average='macro', needs_proba = True, multi_class='ovo'),\n",
    "    'precision_scorer': make_scorer(precision_score, average='macro'),\n",
    "    'recall_scorer': make_scorer(recall_score, average='macro')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processamento principal\n",
    "\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# \n",
    "df_best_results = None\n",
    "best_results = []\n",
    "\n",
    "#print(X.dtype)\n",
    "#print(Y.dtype)\n",
    "\n",
    "for model_name, model_parameters in models_parameters.items():\n",
    "    print(f'>>>>>>>>>> Processing model {model_name}.')\n",
    "    classifier = GridSearchCV(model_parameters['model'], model_parameters['params'], cv=cv, scoring=scoring, refit='roc_auc_ovr_scorer', n_jobs=-1)\n",
    "    classifier.fit(X, y)\n",
    "    y_pred = classifier.predict(X)\n",
    "    \n",
    "    # Gera dataframe de todos os resultados obtidos para cada combinação de parâmetros \n",
    "    results = pd.DataFrame(classifier.cv_results_)\n",
    "    \n",
    "    #print('Results\\n')\n",
    "    #print(results)\n",
    "    #print('\\n')\n",
    "    \n",
    "    # Seleciona o melhor resultado (combinação de parâmetros) com base no scorer 'roc_auc_ovr_scorer'\n",
    "    \n",
    "    results = results.sort_values(by=['rank_test_roc_auc_ovr_scorer'])\n",
    "    \n",
    "    best_result = results.head(1)\n",
    "    \n",
    "    #print('Best result\\n')\n",
    "    #print(best_result)\n",
    "    #print('\\n')\n",
    "    \n",
    "    # Guarda as médias das métricas para o melhor resultado\n",
    "    \n",
    "    mean_test_roc_auc_ovr_scorer = best_result['mean_test_roc_auc_ovr_scorer']\n",
    "    #mean_test_roc_auc_ovo_scorer = best_result['mean_test_roc_auc_ovo_scorer']\n",
    "    mean_test_precision_scorer = best_result['mean_test_precision_scorer']\n",
    "    mean_test_recall_scorer = best_result['mean_test_recall_scorer']\n",
    "    \n",
    "    # CALCULA O ÍNDICE DE CONFIANÇA DO MELHOR RESULTADO PARA CADA MÉTRICA\n",
    "    IC_ROC_OVR=[]\n",
    "    #IC_ROC_OVO=[]\n",
    "    IC_PRECISION=[]\n",
    "    IC_RECALL=[]\n",
    "    \n",
    "    vrocovr=[]\n",
    "    #vrocovo=[]\n",
    "    vprecision=[]\n",
    "    vrecall=[]\n",
    "    \n",
    "    for i in range(0,k):\n",
    "        vrocovr.append(best_result['split' + str(i) + '_test_roc_auc_ovr_scorer'].values)\n",
    "        #vrocovo.append(best_result['split' + str(i) + '_test_roc_auc_ovo_scorer'].values)\n",
    "        vprecision.append(best_result['split' + str(i) + '_test_precision_scorer'].values)\n",
    "        vrecall.append(best_result['split' + str(i) + '_test_recall_scorer'].values)\n",
    "    \n",
    "    IC_ROC_OVR = sms.DescrStatsW(vrocovr).tconfint_mean(alpha=0.05)\n",
    "    #IC_ROC_OVO = sms.DescrStatsW(vrocovo).tconfint_mean(alpha=0.05)\n",
    "    IC_PRECISION = sms.DescrStatsW(vprecision).tconfint_mean(alpha=0.05)  \n",
    "    IC_RECALL = sms.DescrStatsW(vrecall).tconfint_mean(alpha=0.05)\n",
    "    \n",
    "    #print('Confidence interval\\n')\n",
    "    #print(IC_ROC_OVR)\n",
    "    #print(IC_ROC_OVO)\n",
    "    #print(IC_PRECISION)\n",
    "    #print(IC_RECALL)\n",
    "    #print('\\n')\n",
    "    \n",
    "    # DEFINE MATRIZ DE CONFUSÃO\n",
    "    confusion_matrix_test = pd.DataFrame(confusion_matrix(y, y_pred, labels=[0,1,2]), columns = ['SAN', 'CMD', 'CMH'], index = ['SAN', 'CMD', 'CMH'])\n",
    "    \n",
    "    print('Confusion matrix\\n')\n",
    "    print(confusion_matrix_test)\n",
    "    print('\\n')\n",
    "    \n",
    "    # EXIBE GRÁFICO - ROC AUC OVR\n",
    "    \n",
    "    vrocovr_u = []\n",
    "    \n",
    "    for i in range(len(vrocovr)):\n",
    "        vrocovr_u.append(vrocovr[i][0])\n",
    "    \n",
    "    x = range(len(vrocovr_u))\n",
    "    \n",
    "    mean = mean_test_roc_auc_ovr_scorer.values[0]\n",
    "    \n",
    "    plt.figure(figsize=(16,10))\n",
    "    \n",
    "    plt.xlabel('Split', fontsize=15)\n",
    "    plt.ylabel('ROC AUC', fontsize=15)\n",
    "    \n",
    "    plt.ylim(0.0, 1.0)\n",
    "    \n",
    "    plt.xticks(np.arange(0, len(vrocovr_u), 1))\n",
    "    plt.yticks(np.arange(0.0, 1.1, 0.1))\n",
    "    \n",
    "    plt.title(f'Dataset: {dataset}\\n' + f'Model: {model_name}\\n' + f'ROC AUC values by fold', fontsize=15)\n",
    "    \n",
    "    plt.bar(x, vrocovr_u, 0.35, color=\"blue\")\n",
    "    \n",
    "    for i in x:\n",
    "        plt.text(i,round(float(vrocovr_u[i]),4),round(float(vrocovr_u[i]),4))\n",
    "    \n",
    "    plt.axhline(mean, color='red', ls='dotted', label=f'Mean: {round(float(mean),4)}')\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(f'../Resultados/graph_{model_name}_{dt_string}_roc_auc_ovr_splits.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # EXIBE GRÁFICO - PRECISION\n",
    "    \n",
    "    vprecision_u = []\n",
    "    \n",
    "    for i in range(len(vprecision)):\n",
    "        vprecision_u.append(vprecision[i][0])\n",
    "    \n",
    "    x = range(len(vprecision_u))\n",
    "    \n",
    "    mean = mean_test_precision_scorer.values[0]\n",
    "    \n",
    "    plt.figure(figsize=(16,10))\n",
    "    \n",
    "    plt.xlabel('Split', fontsize=15)\n",
    "    plt.ylabel('Precision', fontsize=15)\n",
    "    \n",
    "    plt.ylim(0.0, 1.0)\n",
    "    \n",
    "    plt.xticks(np.arange(0, len(vprecision_u), 1))\n",
    "    plt.yticks(np.arange(0.0, 1.1, 0.1))\n",
    "    \n",
    "    plt.title(f'Dataset: {dataset}\\n' + f'Model: {model_name}\\n' + f'Precision values by fold', fontsize=15)\n",
    "    \n",
    "    plt.bar(x, vprecision_u, 0.35, color=\"blue\")\n",
    "    \n",
    "    for i in x:\n",
    "        plt.text(i,round(float(vprecision_u[i]),4),round(float(vprecision_u[i]),4))\n",
    "    \n",
    "    plt.axhline(mean, color='red', ls='dotted', label=f'Mean: {round(float(mean),4)}')\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(f'../Resultados/graph_{model_name}_{dt_string}_precision_splits.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # EXIBE GRÁFICO - RECALL\n",
    "    \n",
    "    vrecall_u = []\n",
    "    \n",
    "    for i in range(len(vrecall)):\n",
    "        vrecall_u.append(vrecall[i][0])\n",
    "    \n",
    "    x = range(len(vrecall_u))\n",
    "    \n",
    "    mean = mean_test_recall_scorer.values[0]\n",
    "    \n",
    "    plt.figure(figsize=(16,10))\n",
    "    \n",
    "    plt.xlabel('Split', fontsize=15)\n",
    "    plt.ylabel('Recall', fontsize=15)\n",
    "    \n",
    "    plt.ylim(0.0, 1.0)\n",
    "    \n",
    "    plt.xticks(np.arange(0, len(vrecall_u), 1))\n",
    "    plt.yticks(np.arange(0.0, 1.1, 0.1))\n",
    "    \n",
    "    plt.title(f'Dataset: {dataset}\\n' + f'Model: {model_name}\\n' + f'Recall values by fold', fontsize=15)\n",
    "    \n",
    "    plt.bar(x, vrecall_u, 0.35, color=\"blue\")\n",
    "    \n",
    "    for i in x:\n",
    "        plt.text(i,round(float(vrecall_u[i]),4),round(float(vrecall_u[i]),4))\n",
    "    \n",
    "    plt.axhline(mean, color='red', ls='dotted', label=f'Mean: {round(float(mean),4)}')\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(f'../Resultados/graph_{model_name}_{dt_string}_recall_splits.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # ARMAZENA O MELHOR RESULTADO DO MODELO NOS RESULTADOS GERAIS\n",
    "    \n",
    "    best_results.append({\n",
    "        'dataset': dataset,\n",
    "        'model': model_name,\n",
    "        'best_params': classifier.best_params_,\n",
    "        'best_score': f'{round(float(classifier.best_score_),4)}',\n",
    "        'mean_test_roc_auc_ovr': f'{round(float(mean_test_roc_auc_ovr_scorer.values[0]),4)}',\n",
    "        'ci_mean_test_roc_auc_ovr': f'{round(float(IC_ROC_OVR[0]),4)};{round(float(IC_ROC_OVR[1]),4)}',\n",
    "        #'mean_test_roc_auc_ovo': f'{round(float(mean_test_roc_auc_ovo_scorer.values[0]),4)}',\n",
    "        #'ci_mean_test_roc_auc_ovo': f'{round(float(IC_ROC_OVO[0]),4)};{round(float(IC_ROC_OVO[1]),4)}',\n",
    "        'mean_test_precision': f'{round(float(mean_test_precision_scorer.values[0]),4)}',\n",
    "        'ci_mean_test_precision': f'{round(float(IC_PRECISION[0]),4)};{round(float(IC_PRECISION[1]),4)}',\n",
    "        'mean_test_recall': f'{round(float(mean_test_recall_scorer.values[0]),4)}',\n",
    "        'ci_mean_test_recall': f'{round(float(IC_RECALL[0]),4)};{round(float(IC_RECALL[1]),4)}'\n",
    "    })\n",
    "\n",
    "df_best_results = pd.DataFrame(best_results, columns = ['dataset',\n",
    "                                                        'model',\n",
    "                                                        'best_params',\n",
    "                                                        'best_score',\n",
    "                                                        'mean_test_roc_auc_ovr',\n",
    "                                                        'ci_mean_test_roc_auc_ovr',\n",
    "                                                        #'mean_test_roc_auc_ovo',\n",
    "                                                        #'ci_mean_test_roc_auc_ovo',\n",
    "                                                        'mean_test_precision',\n",
    "                                                        'ci_mean_test_precision',\n",
    "                                                        'mean_test_recall',\n",
    "                                                        'ci_mean_test_recall'])\n",
    "\n",
    "df_best_results.to_csv(r'../Resultados/results_' + dt_string + '_' + dataset + '.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
